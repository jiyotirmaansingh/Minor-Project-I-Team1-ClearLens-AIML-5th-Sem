require("dotenv").config();
const express = require("express");
const cors = require("cors");
const bodyParser = require("body-parser");
const axios = require("axios");
const connectDB = require("./config/db"); // ðŸ”¹ MongoDB connect
const sessionRoutes = require("./routes/sessionRoutes"); 
const { authRouter } = require("./routes/authRoutes");
const streakRoutes = require("./routes/StreakRoutes");
const leaderboardRoutes = require("./routes/LeaderboardRoute");

const app = express();

// ðŸ”¹ Middleware
app.use(cors());
app.use(express.json());
app.use(bodyParser.json());

// ðŸ”¹ Routes
app.use("/api/sessions", sessionRoutes); 
app.use("/auth", authRouter);            
app.use("/api/streak", streakRoutes);
app.use("/api/leaderboard", leaderboardRoutes);

// ðŸ”¹ Chatbot route (Ollama â†’ Mistral)
app.post("/chat", async (req, res) => {
  try {
    const { message } = req.body;

    const response = await axios.post("http://localhost:11434/api/generate", {
      model: "mistral",
      prompt: message,
      stream: false, // full response
    });

    const reply = response.data.response;
res.json({ reply });

  } catch (err) {
    console.error(
      "âŒ Error communicating with Ollama:",
      err.response ? err.response.data : err.message
    );
    res.status(500).json({ error: "Failed to get a response from the AI model." });
  }
});

// ðŸ”¹ Base route
app.get("/", (req, res) => {
  res.send("ðŸš€ Welcome to CalmCam + Auth + Chat Backend");
});

// ðŸ”¹ Start server
const PORT = process.env.PORT || 8080;
app.listen(PORT, async () => {
  await connectDB(); 
  console.log(`âœ… MongoDB Connected`);
  console.log(`ðŸš€ Server running on http://localhost:${PORT}`);
});
